---
title: "Detrend and Deseaonalise Time Series"
author: "Dario Lepke"
date: "7 7 2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = normalizePath("./../../"))
```
```{r}
set.seed(1234)
library(raster)
library(ggplot2)
library(dplyr)
library(ncdf4)
getwd()
```
Load preprocessed data

```{r}
sst <- brick("data/interim/sst/ersst_setreftime.nc",
             varname= "ssta")
sst
```

Plot some of the time series:
Extract one time series of values for random grid point that is not NA.

```{r}
# in: brick object
# out: random gridcell that is not on land
#      x is longitude, y is latitude

get_random_cell <- function(brick) {
  # get one layer as a raster object
  r <- raster(brick, layer = 1)
  l <- length(r)
  vals <- getValues(r)
  not_na <- which(!is.na(vals))
  rnd_cell <- sample(not_na, 1)
  lonlat <- xyFromCell(r, rnd_cell)
  return(lonlat)
}

sst_cell <- get_random_cell(sst)
```


```{r}
# in: lonlat info of sea grid point
# out: a ggplot of point on map
plot_cell <- function(cell) {
  # Using GGPLOT, plot the Base World Map
  mp <- NULL
  mapWorld <- borders("world", colour="gray50", fill="gray50") # create a layer of borders
  mp <- ggplot() +   mapWorld
  
  #vNow Layer the cities on top
  mp <- mp + geom_point(aes(x=cell[1], y=cell[2]), ,color="blue", size=3)
  mp
}

plot_cell(sst_cell)

```

```{r}
# in: dataset and respective cellpoint
# out: ggplot of time series data for cellpoint
get_ts <- function(data,cell) {
  vals <- c(extract(data,cell))
  return(vals)
}

sst_ts <- get_ts(sst, sst_cell)

plot_ts <- function(ts) {
  df <- as.data.frame(ts)
  df$month <- 1:length(ts)
  ggplot(df, aes(x=month, y=ts)) + geom_point() +
    geom_line() + geom_smooth()
  
}

plot_ts(sst_ts)
```
Deasonalise and detrend one time series SST

We decompose this time series using the stl function,
which in turn uses loess to decompose a time series.
We create a time series object with frequency 12, since
we use monthly observations, looking for a yearly effect?

$$Monthly Temperatures = Seasonal + Trend + Remainder$$
Deasonalise and detrend all time series SST
OPEN

```{r}
plot_stl <- function(values) {
  time_series <- ts(values, frequency = 12)
  time_series %>% stl(t.window = 12, s.window = "periodic", robust = TRUE) %>% forecast::autoplot()
}

plot_stl(sst_ts)
```

We have a strong seasonal component here, as can be seen by the bar on the right hand side of the plots.


For Precip
```{r}
precip <- brick("data/interim/drought/chirps_setreftime.nc", varname = "precip")
#mean_test2 <- calc(test2, fun=mean, na.rm=TRUE)
#plot(mean_test2)
precip
```

choose random cell
```{r}
cell_precip <- get_random_cell(precip)
```

Plot some of the time series
```{r}
plot_cell(cell_precip)
```

```{r}
precip_ts <- get_ts(precip, cell_precip)
plot_ts(precip_ts)
```
```{r}
plot_stl(precip_ts)
```
Her for the precip data we have a stronger trend, than a seasonal effect?


Compute mean of each month for the Precip time series,
get one amazonas rainfall/precip value for each month
Deasonalise and detrend the monthly means

Use stl on each grid cell, get for each grid cell,
monthly detrended and deseasonalised data.

```{r}

# as.matrix, each col is one layer, meaning stl() over
# the rows is stl() on each grid cell time series
brick_to_matrix <- function(brick_object, nlayers) {
  m <- as.matrix(brick_object[[1:nlayers]])
  ind <- apply(m, 1, function(x) all(is.na(x)))
  m <- m[!ind, ]
  if(any(is.na(m))) stop("Matrix still contains NA")
  return(m)
}

decompose_matrix <- function(matrix_with_ts, ncells) {
  # use min here, since if data contained NA (like sst),
  # we removed the NAs (which were grid points on land)
  # so ncell may be bigger than the actual number of 
  # nonempty rows
  ncells <- min(ncells, nrow(matrix_with_ts))
  out <- apply(matrix_with_ts[1:ncells, ], 1, function(x) if(!any(is.na(x))) stl(ts(x, frequency = 13), "periodic"))
}

# List of length "ncells", each has list of 8, we are interested in the dec$time.series[,"remainder"]

get_remainder <- function(list_of_decomposed_ts) {
  l <- length(list_of_decomposed_ts)
  out <- matrix(NA, nrow = l,
                ncol = nrow(list_of_decomposed_ts[[1]]$time.series))
  for (i in 1:l) {
    out[i,] <- c(list_of_decomposed_ts[[i]]$time.series[,"remainder"])
  }
  return(out)
}

decompose_brick <- function(brick, nlayers, ncells) {
  ts_matrix <- brick_to_matrix(brick_object = brick, nlayers = nlayers)
  dec_list <- decompose_matrix(matrix_with_ts = ts_matrix, ncells = ncells)
  remainder <- get_remainder(list_of_decomposed_ts = dec_list)
  return(remainder)
}

```





```{r}
#do 27 layers with all cells, start 12:53, end 12:54
#may
first_27 <- decompose_brick(brick = precip, nlayers = 27, ncells = ncell(precip))
# checl once again if it all good like this


```
```{r}
library(tictoc)
tic()
#decomposed_precip <- decompose_brick(brick = precip, nlayers = nlayers(precip), ncells = ncell(precip))
toc() #took 90s
#saveRDS(decomposed_precip, file = "./../../data/processed/decomposed_precip_data.rds")
#rm(decomposed_precip)
precip <- readRDS("data/processed/decomposed_precip_data.rds")
```
```{r}
# for sst have to check if i clean the matrix from NA rows aka cells and
# then apply decompose to it and create matrix, maybe later add the coordinats as
# info, or I could do that as rownames YESA!! in the data matrix, SCRT

tic()
#decomposed_sst <- decompose_brick(brick = sst, nlayers = nlayers(sst), ncells = ncell(sst))
#saveRDS(decomposed_sst, file = "data/processed/decomposed_sst_data.rds")
toc()
sst <- readRDS("data/processed/decomposed_sst_data.rds")

```

```{r}
# okay so now I have to two data files, I can now fit a model or
# compute the correlation coefficients for 1m, 2m,..,6m
head(precip)[1:5,1:5]
dim(precip)
head(sst)[1:5,1:5]
dim(sst)

# normalize sst?

```


also compute means of precip data easy
```{r}
dim(precip)
precip_means <- apply(precip, 2, mean)
dim(precip_means)
str(precip_means)
plot(precip_means)
plot_ts(precip_means)
```



```{r}
dim(sst)
?cor()
cor(precip_means, sst[1,])
t_corr <- c()
for (i in 1:nrow(sst)) {
  t_corr[i] <- cor(precip_means, sst[i,])
}
max(t_corr)

d <- function(vec, drops) {
  object <- object[]
}

drop_lastn <- function(obj, lastn) {
  lo <- ncol(obj)
  startdrop <- lo - lastn
  obj <- obj[,-c(startdrop:lo)]
  return(obj)
}

compute_corr <- function(target, predictors, delay=0) {
  corr_vec <- c()
  if(delay!=0) {
    target <- target[-c(1:delay)]
    lp <- ncol(predictors)
    startdrop <- lp-delay+1
    predictors <- predictors[,-c(startdrop:lp)]
  }
  for (i in 1:nrow(predictors)) {
    corr_vec[i] <- cor(target, predictors[i,])
  }
  return(corr_vec)
}

nolag <- compute_corr(precip_means, sst,0)
onelag <- compute_corr(precip_means, sst, 1)
twolag <- compute_corr()

corr_matr <- matrix(nrow = 12, ncol = nrow(sst), NA)
for (i in 1:12) {
  corr_matr[i,] <- compute_corr(precip_means, sst, i)
}

dim(corr_matr)
which(corr_matr == max(corr_matr), arr.ind = TRUE)
dim(sst)
df <- data.frame(cbind(precip_means, t(sst)))
ggplot(data = df, aes(y = precip_means, x = sst[10830,])) + geom_point()

```
```{r}
library(glmnet)
df <- data.frame(cbind(precip_means, t(sst)))
varmtx <- model.matrix(precip_means~.-1, data = df)
dim(varmtx)
length(response)
response <- df$precip_means
ridge <- glmnet(x = scale(varmtx), y = response, alpha = 0)
plot(ridge)

```
```{r}
cvfit <- cv.glmnet(x = scale(varmtx), y = response)
plot(cvfit)
```
```{r}
cvfit$lambda.1se
min(cvfit$cvm)
plot(density(log(scale(precip_means))))
plot(density(scale(precip_means)))
```


```{r}
# check size of regression matrix
# 432 times precip, 16020 predictors
# 432 times 16020
ttm <- matrix(1.002, nrow = 432, ncol = 16020)
ttdf <- as.data.frame(ttm)
object.size(ttm)
```

```{r}
object.size(ttdf)
```
```{r}
# trying to estimate runtim for whole precip or sst data on this laptop
library(rbenchmark)
benchmark("27layers" = {
  decompose_brick(brick = precip, nlayers = 27, ncells = 10)
},
"54layers" = {
  decompose_brick(brick = precip, nlayers = 54, ncells = 10)
},
"108layers" = {
  decompose_brick(brick = precip, nlayers = 108, ncells = 10)
},
replications = 1,
columns = c("test", "replications", "elapsed", "relative", "user.self", "sys.self"))

```
```{r}
benchmark("27layers" = {
  decompose_brick(brick = precip, nlayers = 27, ncells = 50)
},
"54layers" = {
  decompose_brick(brick = precip, nlayers = 54, ncells = 50)
},
"108layers" = {
  decompose_brick(brick = precip, nlayers = 108, ncells = 50)
},
replications = 1,
columns = c("test", "replications", "elapsed", "relative", "user.self", "sys.self"))
```

```{r}
comp_fac <- function(brick_object, nc, nl) {
  return(ncell(brick_object)/nc)+(nlayers(brick_object)/nl)
}

comp_fac(precip, 50, 108)
1224*0.87/60/60 #probably will take 30m mins

```

We can use Raster Time Series!!!
rts()
https://cran.r-project.org/web/packages/rts/rts.pdf
https://datacarpentry.org/r-raster-vector-geospatial/12-time-series-raster/

https://rdrr.io/github/ffilipponi/rtsa/man/rtsa.stl.html

```{r}
library(rts)
slice <- precip[[1:38]]
precip

slice <- rts(slice)

netcdf_precip <- nc_open("data/interim/drought/chirps_setreftime.nc")
t <- ncvar_get(netcdf_precip, "time")
netcdf_precip

?convertDateNcdf2R

install.packages("ncdf4.helpers")
?ncdf4.helpers::nc.get.time.series()

t <- ncdf4.helpers::nc.get.time.series(netcdf_precip)
t <- as.Date.POSIXct(t)
rts_test <- rts(precip, t)
rtsa::rtsa.stl(rts_test)


```
