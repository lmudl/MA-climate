[["index.html", "Predicting Droughts in the Amazon Basin based on Global Sea Surface Temperatures Introduction", " Predicting Droughts in the Amazon Basin based on Global Sea Surface Temperatures Dario Lepke Introduction With future climate change droughts in the Amazon forest may become more frequent and/or severe. Droughts can turn Amazon regions from rain forest into savanna, leading to high amounts of carbon released into the atmosphere. Therefore, predicting future droughts and understanding the underlying mechanisms is of great interest. Ciemer et al. (2020), established an early warning indicator for droughts in the central Amazon basin (CAB), based on tropical Atlantic sea surface temperatures (SSTs). In my thesis I would like to build on this work and improve the predictive power by using different statistical methods. Meaning, we seek to build a model that is able to predict droughts (resp. rainfall) based on preceding sea temperatures, desirably with as much lead time as possible. Also we want to identify those sea regions that are most important for doing so, making interpretability a point of interest, too. A first model could be a cross-validated (generalised) LASSO approach trying to identify the most important oceanic regions and the respective time-scales. The thesis will be done in cooperation with Dr.Â Niklas Boers from the Postdam Institute for Climate Impact Research (Climate Impact Research (PIK) e. V. (2021)). "],["related-work.html", "1 Related work", " 1 Related work As already mentioned the paper by Ciemer et al. (2020), created an early warning indicator for Amazon droughts. They did so using a complex network approach. They used two datasets, one for the Sea Surface Temperatures (Smith et al. (2008)) and one for the precipitation (Funk et al. (2015)) with monthly data for the time period of 1981 until 2016. The data can be downloaded for example in netcdf format and manipulated conveniently with Climate Data Operators (CDO, Schulzweida (2019)). CDO in turn can be used with wrappers for R and Python. The data is organized on a longitude/latitude grid. They identify 4 oceanic regions that correlate the most with rain in the amazon basin, using a coupled network approach. Figure 1.1 shows the cross degree towards rainfall in the central Amazon basin (CAB, blue box), for positive and negative correlations. Darker shades indicate a larger cross degree, hence a larger number of links and correlations with rainfall at more grid points in the CBA. The correlations are measured using a spearman rank-order correlation coefficient \\[\\begin{equation} \\rho = 1 - \\frac{6\\sum\\Delta_{R_i}^2}{n(n^2-1)} . \\tag{1.1} \\end{equation}\\] Where \\(\\Delta_{R_i}\\) denotes the difference between the ranks of observations of both variables at the same time \\(i\\) and \\(n\\) is the number of observations. An Adjacency Matrix describes the resulting network, where the threshold \\(p_{th}\\) was chosen so that only 10% of the strongest correlations are represented as links in the network \\[\\begin{equation} A_{ij} = \\begin{cases}0 \\textrm{ } p_{ij} &lt; p_{th}\\\\ 1 \\textrm{ } p_{ij}\\geq p_{th}\\\\\\end{cases} . \\tag{1.2} \\end{equation}\\] The cross degree then gives the strength of correlation between a specific grid point \\(i\\) of network \\(V_l\\) (oceanic grid point) and another (sub)network \\(V_m\\) (all grid points \\(j\\) in central amazon basin) \\[\\begin{equation} k_{i}^{lm} = \\sum\\limits_{j \\in V_m} A_{ij}, i \\in V_l\\ . \\tag{1.3} \\end{equation}\\] Figure 1.1: Cross degree between sea surface temperature and continental rainfall anomalies. For each sea surface temperature grid cell of the Atlantic and Pacific Ocean, the cross degree towards rainfall in the Central Amazon Basin (blue box) is shown, for a positive correlations and b negative correlations. Darker shading indicates a larger cross degree, implying a larger number of links, and thus significant correlations with rainfall at more grid points in the Central Amazon Basin. Red areas outline coherent oceanic regions with a the 20% highest cross degrees for positive correlations, found in the Southern Pacific Ocean (SPO) and Southern Tropical Atlantic Ocean (STAO), and b the 20% highest cross degrees for negative correlations, found in the Central Pacific Ocean (CPO) and Northern Tropical Atlantic Ocean (NTAO) (Ciemer et al. 2020) They further explore the relationship by constructing (weighted) networks for sliding windows of 24 months between the Central Amazon Basin and each of the ocean regions. For each month except for the first two years, an individual network is computed based on the data of the previous 24 months. Then they take the average of the cross correlations for each of the networks which gives a new time series of average cross correlation (ACC) values. Each ACC summarizes the connectivity of one region with the CAB for the last 24 months. They find that NTAO and STAO give the strongest signal, hence they apply the same sliding window coupled network approach between the ocean regions NTAO and STAO. Before they computed networks between ocean and continental regions, now it is computed between these two Atlantic regions, NTAO and STAO. The resulting time series and its comparison to the drought index time series is shown in figure 1.2 below. They find that using a ACC threshold for a drought (SPI below -1.5), lets them forecast 6 of the 7 droughts in the observation period, missing the 2005 drought, while also giving one false alarm in 2002. Figure 1.2: Early-warning signal for droughts in the central Amazon basin. We compare the time evolution of the average cross correlation of the Northern Tropical Atlantic Ocean (NTAO) and Southern Tropical Atlantic Ocean (STAO), given by the blue curve, with the standardized precipitation index (SPI, orange) of the central Amazon basin. Orange dips indicate a negative SPI with a threshold for severely dry periods (SPI -1, dotted red line). We expect a drought event within the following one and a half years whenever the average cross correlation between NTAO and STAO SST anomalies falls below an empirically found threshold of -0.06. Green circles indicate a matching forecast based on the Atlantic SST correlation structure, with one false alarm in 2002 indicated by a grey circle, where the threshold is crossed but no drought took place in the direct aftermath (see Discussion). The temporal evolution of the average cross correlation shown here is smoothed using a Chebyshev type-I low-pass filter with a cutoff at 24 months (Ciemer et al. 2020). The work by Ciemer et al. (2020) shows potential forecasting capabilities and limitations. While they are able to predict 5 out of 6 drought events, they also give one false negative and one false positive result. Their work uses a complex network approach that is applied stepwise (first two unweighted networks, then two weighted networks and in the end a dichotomous threshold decision rule). For the thesis we would like to create a more general predictive model that can learn the relationship between the SSTs and rainfall in the CAB. As already mentioned a first step can be a LASSO model. First findings show that, the classic LASSO only chooses single points in the ocean as predictors, though. But our motivation is to discover predictive regions and not only single separated points. Therefore in a next step we want to make use of a generalized form of the LASSO that also takes into account that chosen predictors should be close to each other. This model is the so called Fused LASSO. For the models we also need a form of evaluation. Classic Cross Validation assumes independence of the observations. In our setting this is clearly violated due to the time dependency of the data. We will explore different possibilities to use an adjusted form of Cross Validation that takes this characteristic into account. Depending on how well the relationship between SST and rain can be established, we can take this a step further and use it as a so called Emergent Constraint (EC). Since different climate models give different answers about future climate there is a need to narrow this spread, which can be done by ECs. To do so, we need a plausible relationship between a Variable X and Y (here: SST and drought). According to how well the relationship is represented in a climate model we assign credibility to a climate models future projections (here: projections of future droughts in the Amazon rain forest). In summary this can be used to reduce uncertainty in the ensemble of climate models future projections, f.e by using ML techniques as done by Schlund et al. (2020). "],["eda-precipitation.html", "2 EDA precipitation 2.1 Overview 2.2 Precipitation values raw 2.3 Mean at each location 2.4 SD at each location 2.5 Mean and SD at each location 2.6 Trend at each location 2.7 Means per month TEST 2.8 SD per month TEST 2.9 Trend per month TEST", " 2 EDA precipitation In this section we want study the time series of precipitation in the Central Amazon Basin. The CHIRPS data set contains the precipitation data, created from in-situ and satellite measurements (Funk et al. (2015)). It can be downloaded for example from here [https://www.chc.ucsb.edu/data/chirps]. It contains observations from 1981 to 2021. Data comes on a high resolution of 0.05 grid. Time frame: 1980 to 2016 2.1 Overview Below the area of the Central Amazon Basin that is object of our study. Figure 2.1: Localisation of the area under study. The central amazon basin (CAB) spanning across 0,-10 latitude and -70,-55 longitude 2.2 Precipitation values raw Firstly we inspect the precipitation values in general Its form is a unimodal, right-skewed distribution. The values range from r[1] tom r[2]. 2.3 Mean at each location Figure 2.2: Precipitation mean at each location. The mean was computed over the whole time period Figure 2.3: Density of means, means were computed for each location over the whole time period As we can see most locations have a mean precipitation of around 200 mm/month, over the whole time series. Regionally in the upper left corner of the Amazon Basin, mean precipitation is higher or equal to the mean. The reference point for higher is the mean of the location means. This region seems to be more or less spatially consistent. The rest of the region with lower mean precipitation has also some small areas where precipitation is again a little bit higher. For example in the upper right corner and on the bottom, right of the middle. 2.4 SD at each location Figure 2.4: Precipitation standard deviation at each location. The standard deviation was computed over the whole time period Figure 2.5: Density of standard deviations, standard deviations were computed for each location over the whole time period For the standard deviation we also see regional patterns. These patterns overlap with the regions of the mean but their magnitude is flipped. Meaning, in the upper left where we observe larger mean values we generally observe lower standard deviation and in the lower and upper right corners, higher standard deviations. Question: There are obviously regional differences in magnitude of mean and standard deviations. Should we therefore NOT normalise the time series, prior to clustering? Mean and SD contain information and the variables are all measured on the same scale. (Consideration: seasonality might play a role, meaning that the values of different months come a different distribution) 2.5 Mean and SD at each location 2.6 Trend at each location Many regions dont have a trend and trends in general seem to be quite small. We can identify some regions with similar up or downward trends. We also computed plots for the deseasonalised data but it looked almost the same Plot means and sd for each month respectively 2.7 Means per month TEST We see spatial patterns of the mean evolving over time. For example: From May until August there is a spatial separation in two parts that dissolves in september. As expected there is a large seasonal component regarding the means. 2.8 SD per month TEST For the standard deviation we see as well large differences in values during different months of the year. 2.9 Trend per month TEST "],["eda-sst.html", "3 EDA SST 3.1 SST values raw 3.2 Mean at each location 3.3 SD at each location 3.4 Mean and SD at each location 3.5 Trend at each location 3.6 SD per month TEST 3.7 Trend per month TEST", " 3 EDA SST We explore the sea surface temperature data set, used in the paper by Ciemer et al (Ciemer et al. (2020)). ERSST (Extended Reconstructed Sea Surface Temperature, Huang et al. (2017)) is a reanalysis from observed data given in the International Comprehensive Ocean-Athmosphere Data Set (ICOADS). Which contains observations from 1800/01 until 2016/12, made by ships and buoys for example. The data comes on a 2x2 degree grid, where data was missing interpolation techniques were used. See paper for reference. the file contains two variables that are measured across different dimensions. The two variables contain the sea surface temperatures and the respective SST anomalies (with respect to the 1971-2000 monthly climatology). 3.1 SST values raw 3.2 Mean at each location 3.3 SD at each location Figure 3.1: SST standard deviation at each location. The standard deviation was computed over the whole time period Figure 3.2: Density of standard deviations, standard deviations were computed for each location over the whole time period 3.4 Mean and SD at each location Figure 3.3: Mean and SD on the spatial map. 3.5 Trend at each location ## Means per month TEST We see spatial patterns of the mean evolving over time. For example: From May until August there is a spatial separation in two parts that dissolves in september. As expected there is a large seasonal component regarding the means. 3.6 SD per month TEST For the standard deviation we see as well large differences in values during different months of the year. 3.7 Trend per month TEST "],["glyph-plots.html", "4 Glyph plots", " 4 Glyph plots Figure 4.1: Glyph map of seasonal precipitaton pattern. Each location is presented by a time series. The time series are seperated by boxes. The gray reference lines inside the boxes show the mid-range for easier comparison. The above figure is a glyph-map of seasonal precipitation patterns (averages for each month) in the Central Amazon Basin. The gray reference lines show the mid-range for easier comparison of the patterns. We see differences in the seasonal patterns across the map. In the upper left for example, the seasonal patterns stay above mid-range while on the bottom-left they have values clearly towards the low end of the range. Also some areas have multimodal patterns. The patterns differ in range and month of maximum and minimum precipitation. Figure 4.2: Glyph map of de-seasonalised and smoothed precipitation. Each location is presented by a time series. The time series are seperated by boxes. The gray reference lines inside the boxes show the mid-range for easier comparison. The time series are scaled globally, same positions inside the cells correspond to the same values in all locations. This plot shows the smoothed de-seasonalized monthly precipitation, after global scaling. The same position within each cell corresponds to the same value in all locations. Some areas have almost a linear course, increasing, decreasing or constant. Others show a more wiggly courses. As overall pattern we can see that the forms of the patterns have a spatial connection, patterns are close to similar patterns, at the same latitude. Also regarding latitude the closer to the equator the less precipitation. Figure 4.3: Glyph map of de-seasonalised and smoothed precipitation. The time series are scaled locally, ranges are not the same in all cells. The different ranges are given in color shades, where lighter shading indicates a larger range and darker shades smaller ranges. Now we inspect the glyph-map with de-seasonalized locally scaled values. This form of scaling emphasizes the individual shapes. Because of the applied scaling, big patterns may be just be tiny effects. Therefore colors are added according to range. Areas with lighter color have larger ranges than darker areas. The areas with steep linear increases and decreases have smaller ranges than or example the areas below -2.5 latitude in the left. "],["correlation-analysis.html", "5 Correlation analysis 5.1 Short Recap 5.2 Correlation of Sea Surface Temperature and Precipitation 5.3 Summary", " 5 Correlation analysis 5.1 Short Recap We give a short overview over the correlation between monthly sea surface temperature and monthly mean precipitation in the Central Amazonas Basin (CAB). First we will analyse the original and then the deaseasonalised data. SST and precipitation data have been deseasonalised, meaning first each time series was decomposed by the stl algorithm according to \\[Monthly \\textit{ } Data = Seasonal + Trend + Remainder\\] Afterwards only trends and remainders time series were kept to constitute a new time series that will be used as predictor (sst) and target (precipitation). In a next step we compute the correlations between each sst grid point time series and the mean precipitation time series. Since our goal is to predict the precipitation on the sst information, we are also interested in predicting future precipitation some months ahead. To examine this we also compute the correlations for different time lags. For example we might use January sst data to predict precipitation in June, given a time lag of 6 months. We consider time lags of 0,3,6 and 12 months. And show the density of the correlation values as well as their spatial distribution on a map. We also display the highest positive and negative correlation based on their respective 2.5% and 97.5% quantiles. All correlations that are between these values are set to 0 then. The correlation measure we use is the 5.2 Correlation of Sea Surface Temperature and Precipitation 5.2.1 Original Data Following, for each timelag we show the respective density of correlation values, their location on the map and also the 5% strongest positive and negative correlations. 5.2.1.1 Timelag 0 Inspecting the density plot for timelag 0, we see two modi for correlations, one for negative correlations around -0.8 and one for possitive correlations around 0.8. Also a small spike can be seen for low negative correlations. If we plot these correlations on the respective grid points we see a clear north-south negative-positive correlation distinction. The boarder is organised around the equator. The plot for the strongest 5% of correlations reveals areas with strong positive and negative correlations in the north and south respectively. 5.2.1.2 Timelag 3 The density of correlations for timelag 3, is left-skewed and has two modi that are organised around 0 and -0.125 respectively. The correlation map shows that the high positive and negative correlations are more close to equator here. Note that the legend for the correlationmap is shifted here, because the maximal negative correlation has a higher absolute value than the maximal positive correlation. The strongest correlations also seem to be shifted towards the equator. 5.2.1.3 Timelag 6 We can see the density plot for timelag 6 is pretty similar to the one of timelag 0 but seems to be flipped around 0. Similarly the correlation map shows (high) negative correlations in the south now and high postive correlations in the north. 5.2.1.4 Timelag 12 Giving a timelag of one year, we can see that the distribution of correlations is now again similar to the distribution for timelag 0. This also hold for the location of positive and negative correlations in general, as well as for the strongest 5% of correlations. 5.2.2 Deseasonalised Data Following, for each timelag we show the respective density of correlation values, their location on the map and also the 5% strongest positive and negative correlations. 5.2.2.1 Timelag 0 Inspecting the density plot for timelag 0, we see that after excluding seasonality from the time series we get a left-skewed distribution of correlations. With a mode around 0. In general the correlation values are a lot lower than in the original data. With a maximum at around -0.4 and +2.5 respectively. We plot these correlations on the respective grid and see that the clear north south distinction in the correlations before deseasonalising the data does not appear anymore. The plot for the strongest 5% of correlations reveals areas with strongest positive and negative correlations. But as stated before the values are in general much lower. 5.2.2.2 Timelag 3 For the density of timelag 3 we get a similar picture as for timelag 0. The mode is a higher and the tails get a bit more mass. Also the correlation map does not seem to change a lot. The strongest correlations appear to be shifted to the left. 5.2.2.3 Timelag 6 Since the distributions of correlation values are all unimodal we do not observe the flip we saw in the original data when comparing the densities of timelag 0 and 6. The mode again gets larger and the maximum postive and negative correlation values get smaller. The strongest negative correlations are shifted further to left. 5.2.2.4 Timelag 12 Given a timelag of one year, the distribution now has a mode around 6, and started at around 4 when timelag was 0. Also neither the positive nor negative correlations exceed values of 2.5. The consistent region of strong negative and positive correlations is now less organised or more scattered. 5.3 Summary 5.3.1 Original Data We can observe that the positive and negative correlations of sst and precipitation follow a spatial and temporal pattern. The location and density of the positive and negative correlation wanders over the equator in opposite directions. The densities and correlationmaps for timelag 0 and 6 appear to be quite similar but flipped. The densities and correlationmaps for timelag 0 and 12 appear again to be similar. The same pattern seems to hold for the strongest correlations. 5.3.2 Deseasonalised Data Correlation values are in general a lot lower than in the original data and decrease with increasing timelag. We still observe temporal and regional patterns, although these dissolve a bit for a timelag of 12. In this chapter we will first summarize the main ideas of clustering and then apply it to the precipitation data. If not indicated otherwise the information is taken from Elements of Statistical Learning. "],["main-idea-clustering.html", "6 Main Idea Clustering", " 6 Main Idea Clustering We can describe an object by a set of measurements or its similarity to other objects. Using this similarity we can put a collection of objects into subgroups or clusters. The objects in the subgroups should then be more similar to one another than to objects of different subgroups. This means inside the clusters we aim for homogeneity and for observations of different clusters for heterogeneity. With the clustering analysis applied to the precipitation data we want to study if there are distinct groups (regions) apparent in the CAB. So that if we later apply the regression models we predict the precipitation for each group and not for the whole region. To explore the grouping in the data we need a measure of (dis)similarity. This measure is central and depends on subject matter considerations. We construct the dissimilarities based on the measurements taken for each month. We interpret this as a multivariate analysis where, each month is one variable. So given the area in the CAB (resolution 5Â°x5Â°), we have 612 cells and 432 months, resulting in a \\(612 \\times 432\\) data matrix. we want to cluster cells into homogen groups. "],["clustering-methods.html", "7 Clustering Methods 7.1 K-means 7.2 K-medoids 7.3 PCA 7.4 Gap statistic", " 7 Clustering Methods 7.1 K-means In the following we briefly describe the K-means procedure. Beforehand we have to specify a number of clusters \\(C\\) we believe exist in our data. Then we randomly initialize \\(C\\) cluster centers in the feature space. Now two steps are repeated until convergence: For each center we identify the points that are the closest to this center. These points belong now to a cluster \\(C\\). In each cluster we compute the mean of each variable and get a vector of means. This mean vector is now the new center of the cluster. As a measure of dissimilarity we use the Euclidean distance: \\[\\begin{equation} d(x_i,x_{iÂ´}) = \\sum_{j=1}^p(x_{ij}-x_{iÂ´j})^2=||x_i-x_{iÂ´}||^2 \\tag{7.1} \\end{equation}\\] Meaning for the points \\(i\\) and \\(iÂ´\\) we compute the squared difference for each variable and sum them up. As stated above we are searching for clusters that are themselves compact, meaning homogeneous. We do so by minimizing the mean scatter inside the clusters. We summarize this scatter as within-sum-of-squares \\[\\begin{equation} W(C) = \\frac{1}{2} \\sum_{k=1}^{K} \\sum_{C(i)=k} \\sum_{C(iÂ´)=k} ||x_i-x_{iÂ´}||^2 \\\\ = \\sum_{k=1}^K N_k \\sum_{C(i)=k} ||x_i-\\bar{x}_k ||^2 \\tag{7.2} \\end{equation}\\] where \\(\\bar{x} = (\\bar{x}_{1k},...,\\bar{x}_{pk})\\) stands for the mean vectors of the \\(k\\)th cluster and \\(N_k = \\sum_{i=1}^N I(C(i)=k)\\). 7.1.1 Kmeans characteristics variance of each distribution of each attribute (variable) is spherical, variance is symmetrical? all variables have same variance, not the case in our example, therefore scaling or pca equal number of observations in each clusters, we don`t know Since we use the Euclidean distance the similarity measures will be sensitive to outliers and scale. K-means assumes that the variance of a variableÂ´s distribution is spherical, meaning it wight not work well in situations that violate this assumptions (f.e non-spherical data). Further assumptions are same variance of the variables, and equally sized clusters. Now how large these violations have to be so that k-means does not work well anymore has no clear-cut answer. 7.2 K-medoids We can adjust k-means procedure so that we can use other distances than the Euclidean distance. The only part of the k-means algorithm that uses Euclidean distance is when we compute the cluster centers. We can replace this step by formalizing an optimization with respect to the cluster members. For example so that each center has to be one of the observations assigned to the cluster. K-medoids is far more computationally intensive than K-means. 7.2.1 K-medoids characteristics K-medoids is less sensitive to outliers, because it minimizes sum of pairwise dissimilarities instead of sum of squared Euclidean distances. As stated above it is also more computationally intensive. 7.3 PCA Goal is reduction of correlated and eventually large number p variables to a few. We accomplish this by creating new variables that are linear combinations of the original ones. We call these new variables principle components. The new variables are not correlated any more and ordered according to the variance they explain. The first \\(k &lt; p\\) principal components then contain the majority of variance (Fahrmeir et al. (1996)). As they are ordered they also provide a sequence of best linear approximations of our data. Let \\(x_1, x_2,...,x_N\\), be our observations and we represent them by a rank-q linear model \\[\\begin{equation} f(\\lambda) = \\mu + V_q\\lambda \\tag{7.3} \\end{equation}\\] with \\(\\mu\\) a location vector in \\(\\mathbb{R}^p\\) and \\(V_q\\) is a \\(p \\times q\\) matrix with columns being orthogonal unit vectors as columns. \\(\\lambda\\) is a \\(q\\) vector of parameters. In other words we are trying to fit a hyperplane of rank q to the data. If we fit this model to minimize reconstruction error using least squares we solve \\[\\begin{equation} \\min_{\\mu, \\{\\lambda_i\\}, V_q } \\sum_{i=1}^N||x_i - \\mu - V_q\\lambda_i ||^2 \\tag{7.4} \\end{equation}\\] If we partially optimize for \\(\\mu\\) and \\(\\lambda_i\\) we obtain \\[ \\hat{\\mu} = \\bar{x},\\] \\[\\hat{\\lambda_i} = V_q^T(x_i - \\bar{x}) \\] Therefore we need to search for the orthogonal matrix \\(V_q\\) \\[\\begin{equation} \\min_{V_q} \\sum_{i=1}^N ||(x_i-\\bar{x}) - V_qV_q^t(x_i-\\bar{x})||^2 \\tag{7.5} \\end{equation}\\] We can assume here that \\(\\bar{x}\\) is 0, if this not the case we can simply center the observations \\(\\tilde{x}_i = x_i - \\bar{x}\\). \\(H_q = V_qV_q^T\\) projects each observation \\(x_i\\) from the original feature space onto the subspace that is spanned by the columns of \\(V_q\\). \\(H_qx_i\\) is then the orthogonal projection of \\(x_i\\) Hence \\(H_q\\) is also called the projection matrix. We find \\(V_q\\) then by constructing the singular value decomposition of our data matrix X. \\(X\\) contains the (centered) observations in rows, giving a \\(N \\times p\\) matrix. The SVD is then: \\[\\begin{equation} X = UDV^T \\tag{7.6} \\end{equation}\\] Where \\(U\\) is an orthogonal matrix containing the left singular vectors \\(u_j\\) as columns, and \\(V\\) contains the right singular vectors \\(v_j\\). The columns of \\(U\\) span the columns space of \\(X\\) and the columns of \\(V\\) span the row space. \\(D\\) is diagonal matrix which contains singular values, \\(d_1 \\leq d_2 \\leq ... \\leq d_p \\leq 0\\). Singular values are square roots of non-negative eigenvalues. The columns of \\(UD\\) are the principal components of \\(X\\). So the SVD gives us the matrix \\(V\\) (the first \\(q\\) columns give the solution to the minimization problem above) as well as the principal components from \\(UD\\) (Hastie et al. (2009)). 7.4 Gap statistic The idea of the gap statistic was introduced by Tibshirani, Walther, and Hastie (2001) As stated above we usually measure how compact our clusters are by assessing \\(W(C)\\) or \\(log(W_c)\\). Where low values indicate compact clusters. To compare the value then, we need a reference. We therefore want to estimate how large \\(W_c\\) were if there were no clusters present in our data. The larger the difference between the \\(W_c\\) from the data and the one from the reference the more likely we are to say that the found number of clusters is indeed correct. We construct reference data by sampling from a uniform distribution based on our data. Say we have \\(p\\) variables. We sample \\(n\\) times from each of the \\(p\\) uniformly distributed variables, where maximum and minimum are obtained from our data. We then cluster the reference data in the same we cluster our observed data and compute \\(W_c\\). We repeat this process several times and compute the average of \\(W_c\\), \\(E \\{log(W_c)\\}\\). The gap statistic is then the difference \\[\\begin{equation} E \\{log(W_c) \\} - log(W_c). \\tag{7.7} \\end{equation}\\] So in cases where our data is formed of clusters we would expect a high gap statistic. As Tibshirani, Walther, and Hastie (2001) note and as it is also done in the used R function clusgap, doing a PCA on the data and compute the gap statistic on the PCA scores can improves the results of gap statistic. "],["clustering-results.html", "8 Clustering results 8.1 K-means and PAM gap statistics without PCA 8.2 K-means and PAM gap statistics after applying PCA 8.3 Summary", " 8 Clustering results We summarize and compare the results we obtain if we center or dont center the data. 8.1 K-means and PAM gap statistics without PCA Figure 8.1: Gap statistics for different number of clusters k, for the K-means (left) and the PAM (right) algorithm respectively. The dashed line indicates the optimal number of clusters found. We can see that on the original data, neither K-means nor PAM find an optimal number of clusters that is lower than the maximum number specified. 8.1.1 Scree plot Figure 8.2: Scree plot with the principal components on the x-axis and the respective percentage of variance explained on the y-axis. The PCA was done after centering the data.The first three and four PC`s together explain 67.77 and 70.69% of the variance respectively We apply a PCA on the centered data. The variance that is explained by the principal components indicates that, the 3 principal components already explain a lot of the appearing variance in the data. We now study the gap statistic results for K-means and K-medoids (here, meaning PAM) after applying the PCA and choosing the number of principal components to be used. Following we compare the results of a gap statistic when the first 3 and 4 principal components are used, for K-means and PAM respectively. The first three and four PC`s used explain 67.77 and 70.69% of the variance respectively. 8.2 K-means and PAM gap statistics after applying PCA Figure 8.3: Gap statistic plots for K-means and PAM when using 3 and 4 PCs respectively. The graphic shows the gap statistics resulting from K-means and PAM for 3 and 4 principal components respectively. When 3 principal components are used K-means and PAM find 5 and 12 as optimal number of clusters, respectively. When we choose to use the first 4 principal components, both algorithms choose 13 as the optimal number. 8.3 Summary We used the gap statistic as evaluation tool to find the optimal number of clusters in our data. It was applied by using K-means and PAM as cluster algorithms, on the centered data with and without applying a pca beforehand. When applied without PCA, PAM and K-means found the maximal number of clusters optimal, regardless of centering. The results differed regarding centering the data when a PCA was applied. When the data was centered before the PCA, we find 5 and 12 (3 principal components, K-means and PAM, respectively) and 13 (4 principal components, both K-means and PAM) as optimal number of clusters. The results overall vary greatly and are sensitive to choices such as number of principal components, the algorithm and the decision criterion (here Tibshirani, Walther, and Hastie (2001)). The value of the clustering itself can be evaluated only when used in combination with regression. If useful, fitting different models for the different clusters should result in a lower overall average prediction error. We will proceed by using K-means for finding 5 clusters after applying a PCA on the centered data and use 3 principal components. "],["analyse-clustering-results.html", "9 Analyse clustering results", " 9 Analyse clustering results We now analyze further the results we found. Namely the clusters we find after performing a PCA on the data, using the 3 first principal components and searching for 5 clusters using k-means. The first 3 principal components explain 67.8% of the variance We found 5 as optimal number of clusters based on the gap statistic and the criteria from Tibsherani. We show the map plot for the k-means clustering after applying the PCA as well as the time series of the resulting clusters. Figure 9.1: Spatial distribution of the found clusters in the CAB. We applied a centered PCA on the data and used 3 principal components before applying the K-means algorithm The plot above shows the grid cells in the Central Amazon Basin colored according to the clusters that are assigned by k-means. The clusters are almost completely spatially coherent. Meaning that the clusters are not scattered across different areas. One exception can be seen for Cluster 1 and 4. Parts of cluster 1 (orange) are inside cluster 4 (blue) and on the edge to cluster 3 (green). Figure 9.2: Plots of the time series in the clusters we found using the K-means algorithm. The x-axis shows the month of measurement, the y-axis the centered precipitation. Centering was done according to the overall CAB mean in each month. The mean inside each cluster for a month is displayed in blue. We now inspect the original (centered) time series inside the clusters. The time series are shown in gray and the monthly mean in the cluster is shown in blue. Since the time series are centered before applying the PCA and clustering, the zero value is the mean of the respective month of the whole CAB. The clusters differ in their monthly differences from the monthly CAB mean (here 0 because the time series were centered before PCA and K-means) and their fluctuation/ variance. Also the size of the clusters are not all the same. The mean in cluster 3 has lowest variability around the CAB mean, followed by clusters 2 and 5, and clusters 1 and 4 have the highest variability. On average cluster 3 is on the level of the CAB overall mean. The clusters 2 and 5 are slightly below and cluster 4 is above the CAB mean, on average. Cluster 1 is on average also on the CAB mean but shows more variance than cluster 3. "],["lasso-on-original-data.html", "10 Lasso on original data 10.1 LASSO model 10.2 Error plots 10.3 Coefficient plots 10.4 Inspect predictions from each fold 10.5 Inspect predictions from best CV-lambda 10.6 Summary", " 10 Lasso on original data 10.1 LASSO model We fit a LASSO model on the precipitation and SST data. The precipitation target is the monthly mean precipitation in the Central Amazon Basin, the SST data are monthly temperatures over the globe. We use a 5-fold CV approach to find an optimal lambda. Each fold consists of 5 consecutive years of training data followed by 2 years of test data. In each fold we fit a LASSO model on a set of predetermined lambda values and choose the lambda that minimizes the MSE on the test set in that fold. After determining the best lambda in each fold we choose the lambda that minimizes the MSE over all folds and refit the model to the complete training data. Afterwards we evaluate the fitted model on a separate validation set with 5 years length which was not included in the training phase. 10.2 Error plots Figure 10.1: Mean squared error of the 5-fold blocked cross validation for a range of lambda values on the log scale. The points in the middle represent the average MSE for the respective lambda, the errorbars give the MSE +/- one standard deviation. The dotted line shows the lambda for which minimum MSE was obtained. 10.1 shows the results from the 5 fold-CV plotted for each lambda. The lambdas are given on the log scale. The upper and lower bars indicate mean MSE +/- one standard deviation from the mean MSE. We note that the upper and lower bars are quite wide indicating big differences in MSE for the different folds. We therefore also inspect the MSE for each individual fold. Figure 10.2: MSE of the CV for the different lambda values on the a log scale. The red dotted line shows the lambda for which minimum MSE was obtained. At first glance 10.2 shows that the MSE for fold 1 and 2 have similar trajectories, the same for 3 and 4, while fold 5 is the only one that only has a local maximum somewhat in the middle of the log lambda range. But fold 5 also has its minimum MSE at a larger regularization value than the other folds which is also reflected in the number of coefficients it includes in the model, as we will see in the coefficient plots. Also obviously the MSE differ greatly in their values as can be seen on the differences of their respective y-axis. While this plot works well for getting an overview of the trajectories we can replot them with a common y-axis to compare their values more easily. Figure 10.3: MSE of the CV for the different lambda values on the a log scale. The red dotted line shows the lambda for which minimum MSE was obtained. See @ ef(fig:err-folg-lasso-og), but this time the y-axis has the same range for all plots. We can see now that fold 2 settles for far larger errors than fold 5 for example. Fold 5 chooses the highest lambda but also has the lowest minimal MSE. Below we can see the minimum MSE for each fold. ## [1] 480.6819 1375.0218 851.4443 500.4939 293.8763 And which lambda in the lambda vector resulted in the lowest prediction error on the foldsÂ´ test set. ## [1] 2.722045 3.129690 4.137266 3.355864 27.220448 10.3 Coefficient plots Figure 10.4: Coefficient map plot for the different folds. Longitude and Latitude on the x and y-axis respectively. Positive values are coloured in blue, negative values in red. The plots displays the nonzero coefficients in each fold computed for the lambda that minimizes the MSE on the test set in the respective fold. The LASSO chooses among correlated variables only one and discards the others, which can be seen here since the variables chosen are scattered across the map and can but dont have to be close to each other. If we take a look again at ?? we can see that the model includes locations that have high correlations. 10.4 Inspect predictions from each fold Following we inspect the folds precipitation time series and the predictions made by the model. Figure 10.5: Precipitation prediction and target values in the test set in each fold. Predictions in red and target values in black. In general the model fits the data sufficiently to predict the general form of the time series but misses some modes and is off in the larger values in fold 2. Also it does not fit well rapid changes as in fold 3. Therefore it seems that the model generally underfits the data. 10.5 Inspect predictions from best CV-lambda A common practice is too choose the largest lambda so that it`s mean MSE is smaller than the MSE of the lambda that minimizes mean MSE plus one SE. But since in our case the largest lambda that satisfies these criteria is the maximum lambda we choose the lambda with minimum mean MSE instead. ## [1] 1326.809 Over the more than 5 years of validation data the model predicts the seasonal pattern of the precipitation time series quite well, but constantly fails to predict the higher values of precipitation. The MSE is mse_full and the RSME sqrt(mse_full). 10.6 Summary We fitted a LASSO model for predicting the mean precipitation in the Central Amazon Basin and used a 5-fold blocked Cross Validation approach to find the optimal level of regularization. After training the model we evaluated its performance on a separate validation set that was not used in the training process. The model shows predicting capabilities but misses out on higher values of the precipitation target. It also misses on rapid changes and in general underfits the data. This may be due to the choice of blocked cross validation. Locations with higher variability get included in the model more easily and are not necessarily geographically close. ## ## Box-Ljung test ## ## data: res ## X-squared = 29.599, df = 20, p-value = 0.07662 "],["lasso-on-cluster-1.html", "11 Lasso on cluster 1 11.1 Cluster 1 11.2 Error plots 11.3 Coefficient plots 11.4 Inspect predictions from each fold 11.5 Inspect predictions from best CV-lambda 11.6 Summary", " 11 Lasso on cluster 1 11.1 Cluster 1 These are the lasso results for cluster 1 11.2 Error plots Figure 11.1: Mean squared error of the 5-fold blocked cross validation for cluster 1. On the x-axis the lambda values on the log scale. The points in the middle represent the average MSE for the respective lambda, the errorbars give the MSE +/- one standard deviation. The dotted line shows the lambda for which minimum MSE was obtained. 11.1 shows the results from the 5 fold-CV plotted for each lambda. The lambdas are given on the log scale. The upper and lower bars indicate mean MSE +/- one standard deviation from the mean MSE. We note that the upper and lower bars are quite wide indicating big differences in MSE for the different folds, just as in the unclustered case, the minimum average MSE is obtained at a higher lambda value. Again we also inspect the MSE for each individual fold. Figure 11.2: MSE of the CV for the different lambda values on the a log scale. The red dotted line shows the lambda for which minimum MSE was obtained. The trajectories in 11.2 are quite similar in fold 1 4 and 5, but quite different from fold 2 and 3. The chosen values of regularisation differ between the folds. Figure 11.3: MSE of the CV for the different lambda values on the a log scale computed for cluster 1. The red dotted line shows the lambda for which minimum MSE was obtained. See @ ef(fig:err-folg-lasso-og), but this time the y-axis has the same range for all plots. Below we can see the minimum MSE for each fold. And which lambda in the lambda vector resulted in the lowest prediction error on the foldsÂ´ test set. 11.3 Coefficient plots Figure 11.4: Coefficient map plot for the different folds. Longitude and Latitude on the x and y-axis respectively. Positive values are coloured in blue, negative values in red. 11.4 Inspect predictions from each fold Following we inspect the folds precipitation time series and the predictions made by the model. 11.5 Inspect predictions from best CV-lambda We choose now the best lambda and fit the model anew to predict the time series we held out as validation data ## [1] 1616.594 11.6 Summary "],["lasso-with-standardization.html", "12 Lasso with standardization 12.1 Model 12.2 Error plots 12.3 Coefficient plots 12.4 Inspect predictions from each fold 12.5 Inspect predictions from best CV-lambda 12.6 Summary", " 12 Lasso with standardization 12.1 Model We fit a LASSO model on the precipitation and SST data. But in this case we standardize in the glmnet function. 12.2 Error plots Figure 12.1: Mean squared error of the 5-fold blocked cross validation for a range of lambda values on the log scale. The points in the middle represent the average MSE for the respective lambda, the errorbars give the MSE +/- one standard deviation. The dotted line shows the lambda for which minimum MSE was obtained. 12.1 shows the results from the 5 fold-CV plotted for each lambda. The lambdas are given on the log scale. The upper and lower bars indicate mean MSE +/- one standard deviation from the mean MSE. For values of log \\(\\lambda\\) smaller than 0 the differences in MSE become huge. Figure 12.2: MSE of the CV for the different lambda values on the a log scale. The red dotted line shows the lambda for which minimum MSE was obtained. The errors in fold 5 are the ones that explode after lambda 0. Figure 12.3: MSE of the CV for the different lambda values on the a log scale. The red dotted line shows the lambda for which minimum MSE was obtained. See @ ef(fig:err-folg-lasso-og), but this time the y-axis has the same range for all plots. This plot emphasizes the findings from the plot above Below we can see the minimum MSE for each fold. ## [1] 590.0167 1883.5540 775.5926 593.1082 350.5754 And which lambda in the lambda vector resulted in the lowest prediction error on the foldsÂ´ test set. ## [1] 7.75248110 3.35586400 1.26346125 0.08913469 5.46922216 12.3 Coefficient plots Figure 12.4: Coefficient map plot for the different folds. Longitude and Latitude on the x and y-axis respectively. Positive values are coloured in blue, negative values in red. 12.4 Inspect predictions from each fold Following we inspect the folds precipitation time series and the predictions made by the model. Figure 12.5: Precipitation prediction and target values in the test set in each fold. Predictions in red and target values in black. The predictions look similar to those without standardization, with differences for example in fold 2. With standardization the predictions are lower than the target in the later months. But the peak in fold 4 is better fit by this model than by the original lasso. 12.5 Inspect predictions from best CV-lambda For consistency we also choose the minimizing lambda here. ## [1] 1235.727 Over the more than 5 years of validation data the model predicts the seasonal pattern of the precipitation time series quite well, but constantly fails to predict the higher values of precipitation. The MSE is mse_full and the RSME `sqrt(mse_full)``. 12.6 Summary By standardizing we improve the MSE of the final model slightly but still under estimate the larger precipitation values in the evaluation set. ## ## Box-Ljung test ## ## data: res ## X-squared = 26.417, df = 20, p-value = 0.1525 "],["lasso-on-cluster-2.html", "13 Lasso on cluster 2 13.1 Cluster 2 13.2 Error plots 13.3 Coefficient plots 13.4 Inspect predictions from each fold 13.5 Inspect predictions from best CV-lambda 13.6 Summary", " 13 Lasso on cluster 2 13.1 Cluster 2 These are the lasso results for cluster 2 13.2 Error plots Figure 13.1: Mean squared error of the 5-fold blocked cross validation for cluster 2. On the x-axis the lambda values on the log scale. The points in the middle represent the average MSE for the respective lambda, the errorbars give the MSE +/- one standard deviation. The dotted line shows the lambda for which minimum MSE was obtained. Figure 13.2: MSE of the CV for the different lambda values on the a log scale. The red dotted line shows the lambda for which minimum MSE was obtained The trajectories in 13.2 are quite similar in fold 1 4 and 5, but quite different from fold 2 and 3. The chosen values of regularization differ between the folds. Figure 13.3: MSE of the CV for the different lambda values on the a log scale computed for cluster 2. The red dotted line shows the lambda for which minimum MSE was obtained. See @ ef(fig:err-folg-lasso-og), but this time the y-axis has the same range for all plots. Below we can see the minimum MSE for each fold. And which lambda in the lambda vector resulted in the lowest prediction error on the foldsÂ´ test set. 13.3 Coefficient plots Figure 13.4: Coefficient map plot for the different folds. Longitude and Latitude on the x and y-axis respectively. Positive values are coloured in blue, negative values in red. 13.4 Inspect predictions from each fold Following we inspect the folds precipitation time series and the predictions made by the model. 13.5 Inspect predictions from best CV-lambda We choose now the best lambda and fit the model anew to predict the time series we held out as validation data ## [1] 1250.799 13.6 Summary "],["lasso-on-cluster-3.html", "14 Lasso on cluster 3 14.1 Cluster 3 14.2 Error plots 14.3 Coefficient plots 14.4 Inspect predictions from each fold 14.5 Inspect predictions from best CV-lambda 14.6 Summary", " 14 Lasso on cluster 3 14.1 Cluster 3 These are the LASSO results for cluster 3 14.2 Error plots Figure 14.1: Mean squared error of the 5-fold blocked cross validation for cluster 3. On the x-axis the lambda values on the log scale. The points in the middle represent the average MSE for the respective lambda, the errorbars give the MSE +/- one standard deviation. The dotted line shows the lambda for which minimum MSE was obtained. Figure 14.2: MSE of the CV for the different lambda values on the a log scale. The red dotted line shows the lambda for which minimum MSE was obtained. The trajectories in 14.2 are quite similar in fold 1 4 and 5, but quite different from fold 2 and 3. The chosen values of regularisation differ between the folds. Figure 14.3: MSE of the CV for the different lambda values on the a log scale computed for cluster 3. The red dotted line shows the lambda for which minimum MSE was obtained. See @ ef(fig:err-folg-lasso-og), but this time the y-axis has the same range for all plots. Below we can see the minimum MSE for each fold. And which lambda in the lambda vector resulted in the lowest prediction error on the foldsÂ´ test set. 14.3 Coefficient plots Figure 14.4: Coefficient map plot for the different folds. Longitude and Latitude on the x and y-axis respectively. Positive values are coloured in blue, negative values in red. 14.4 Inspect predictions from each fold Following we inspect the folds precipitation time series and the predictions made by the model. 14.5 Inspect predictions from best CV-lambda We choose now the best lambda and fit the model anew to predict the time series we held out as validation data ## [1] 3091.448 14.6 Summary "],["lasso-on-cluster-4.html", "15 Lasso on cluster 4 15.1 Cluster 4 15.2 Error plots 15.3 Coefficient plots 15.4 Inspect predictions from each fold 15.5 Inspect predictions from best CV-lambda 15.6 Summary", " 15 Lasso on cluster 4 15.1 Cluster 4 These are the LASSO results for cluster 4 15.2 Error plots Figure 15.1: Mean squared error of the 5-fold blocked cross validation for cluster 4. On the x-axis the lambda values on the log scale. The points in the middle represent the average MSE for the respective lambda, the errorbars give the MSE +/- one standard deviation. The dotted line shows the lambda for which minimum MSE was obtained. Figure 15.2: MSE of the CV for the different lambda values on the a log scale. The red dotted line shows the lambda for which minimum MSE was obtained. Figure 15.3: MSE of the CV for the different lambda values on the a log scale computed for cluster 4. The red dotted line shows the lambda for which minimum MSE was obtained. See @ ef(fig:err-folg-lasso-og), but this time the y-axis has the same range for all plots. Below we can see the minimum MSE for each fold. And which lambda in the lambda vector resulted in the lowest prediction error on the foldsÂ´ test set. 15.3 Coefficient plots Figure 15.4: Coefficient map plot for the different folds. Longitude and Latitude on the x and y-axis respectively. Positive values are coloured in blue, negative values in red. 15.4 Inspect predictions from each fold Following we inspect the folds precipitation time series and the predictions made by the model. 15.5 Inspect predictions from best CV-lambda We choose now the best lambda and fit the model anew to predict the time series we held out as validation data ## [1] 3505.33 15.6 Summary "],["lasso-on-cluster-5.html", "16 Lasso on cluster 5 16.1 Cluster 5 16.2 Error plots 16.3 Coefficient plots 16.4 Inspect predictions from each fold 16.5 Inspect predictions from best CV-lambda 16.6 Summary", " 16 Lasso on cluster 5 16.1 Cluster 5 These are the cluster results for cluster 5 16.2 Error plots Figure 16.1: Mean squared error of the 5-fold blocked cross validation for cluster 5. On the x-axis the lambda values on the log scale. The points in the middle represent the average MSE for the respective lambda, the errorbars give the MSE +/- one standard deviation. The dotted line shows the lambda for which minimum MSE was obtained. Figure 16.2: MSE of the CV for the different lambda values on the a log scale. The red dotted line shows the lambda for which minimum MSE was obtained. Figure 16.3: MSE of the CV for the different lambda values on the a log scale computed for cluster 5. The red dotted line shows the lambda for which minimum MSE was obtained. See @ ef(fig:err-folg-lasso-og), but this time the y-axis has the same range for all plots. Below we can see the minimum MSE for each fold. And which lambda in the lambda vector resulted in the lowest prediction error on the foldsÂ´ test set. 16.3 Coefficient plots Figure 16.4: Coefficient map plot for the different folds. Longitude and Latitude on the x and y-axis respectively. Positive values are coloured in blue, negative values in red. 16.4 Inspect predictions from each fold Following we inspect the folds precipitation time series and the predictions made by the model. 16.5 Inspect predictions from best CV-lambda We choose now the best lambda and fit the model anew to predict the time series we held out as validation data ## [1] 2599.921 16.6 Summary "],["lasso-with-lags.html", "17 lasso with lags 17.1 LASSO model with lags 17.2 Error plots 17.3 Coefficient plots 17.4 Inspect predictions from each fold 17.5 Inspect predictions from best CV-lambda 17.6 Summary", " 17 lasso with lags 17.1 LASSO model with lags We fit a LASSO model on the precipitation and SST data. This time we include lags from 1 to 3 and a rolling mean of 3 17.2 Error plots Figure 17.1: Mean squared error of the 5-fold blocked cross validation for a range of lambda values on the log scale. The points in the middle represent the average MSE for the respective lambda, the errorbars give the MSE +/- one standard deviation. The dotted line shows the lambda for which minimum MSE was obtained. Figure 17.2: MSE of the CV for the different lambda values on the a log scale. The red dotted line shows the lambda for which minimum MSE was obtained. Figure 17.3: MSE of the CV for the different lambda values on the a log scale. The red dotted line shows the lambda for which minimum MSE was obtained. See @ ef(fig:err-folg-lasso-og), but this time the y-axis has the same range for all plots. Below we can see the minimum MSE for each fold. ## [1] 13894.94 14232.87 13067.59 11659.02 18720.08 And which lambda in the lambda vector resulted in the lowest prediction error on the foldsÂ´ test set. ## [1] 72.2998982 72.2998982 0.0722999 72.2998982 72.2998982 17.3 Coefficient plots coefficient plot function TODO 17.4 Inspect predictions from each fold Following we inspect the folds precipitation time series and the predictions made by the model. Figure 17.4: Precipitation prediction and target values in the test set in each fold. Predictions in red and target values in black. 17.5 Inspect predictions from best CV-lambda ## [1] 1910.708 MSE is mse_full RMSE sqrt(mse_full) 17.6 Summary "],["lasso-with-diff.html", "18 lasso with diff 18.1 LASSO model with diff 18.2 Error plots 18.3 Coefficient plots 18.4 Inspect predictions from each fold 18.5 Inspect predictions from best CV-lambda 18.6 Summary", " 18 lasso with diff 18.1 LASSO model with diff LASSO model, SST data gets differentiated twice to obtain stationary features. 18.2 Error plots Figure 18.1: Mean squared error of the 5-fold blocked cross validation for a range of lambda values on the log scale. The points in the middle represent the average MSE for the respective lambda, the errorbars give the MSE +/- one standard deviation. The dotted line shows the lambda for which minimum MSE was obtained. Figure 18.2: MSE of the CV for the different lambda values on the a log scale. The red dotted line shows the lambda for which minimum MSE was obtained. Figure 18.3: MSE of the CV for the different lambda values on the a log scale. The red dotted line shows the lambda for which minimum MSE was obtained. See @ ef(fig:err-folg-lasso-og), but this time the y-axis has the same range for all plots. Below we can see the minimum MSE for each fold. ## [1] 673.0635 2415.5896 1298.1890 2005.2224 624.3438 And which lambda in the lambda vector resulted in the lowest prediction error on the foldsÂ´ test set. ## [1] 2.5385880 1.3547681 0.4436255 2.7220448 5.1006149 18.3 Coefficient plots Figure 18.4: Coefficient map plot for the different folds. Longitude and Latitude on the x and y-axis respectively. Positive values are coloured in blue, negative values in red. 18.4 Inspect predictions from each fold Following we inspect the folds precipitation time series and the predictions made by the model. Figure 18.5: Precipitation prediction and target values in the test set in each fold. Predictions in red and target values in black. In general the model fits the data sufficiently to predict the general form of the time series but misses some modes and is off in the larger values in fold 2. Also it does not fit well rapid changes as in fold 3. Therefore it seems that the model generally underfits the data. 18.5 Inspect predictions from best CV-lambda We choose now the best lambda with the 1SE rule and fit the model anew to predict the time series we held out as validation data ## [1] 1603.011 MSE mse_full RMSE sqrt(mse_full) 18.6 Summary We fitted a LASSO model for predicting the mean precipitation in the Central Amazon Basin and used a 5-fold blocked Cross Validation approach to find the optimal level of regularization. After training the model we evaluated its performance on a separate validation set that was not used in the training process. The model shows predicting capabilities but misses out on higher values of the precipitation target. It also misses on rapid changes and in general underfits the data. This may be due to the choice of blocked cross validation. Locations with higher variability get included in the model more easily and are not necessarily geographically close. "],["lasso-with-deseasonalised.html", "19 lasso with deseasonalised 19.1 LASSO model, stl() on SST 19.2 Error plots 19.3 Coefficient plots 19.4 Inspect predictions from each fold 19.5 Inspect predictions from best CV-lambda 19.6 Summary", " 19 lasso with deseasonalised 19.1 LASSO model, stl() on SST LASSO model, fit on the remainder time series of the SST data, obtained by applying the STL algorithm. 19.2 Error plots Figure 19.1: Mean squared error of the 5-fold blocked cross validation for a range of lambda values on the log scale. The points in the middle represent the average MSE for the respective lambda, the errorbars give the MSE +/- one standard deviation. The dotted line shows the lambda for which minimum MSE was obtained. Figure 19.2: MSE of the CV for the different lambda values on the a log scale. The red dotted line shows the lambda for which minimum MSE was obtained. Figure 19.3: MSE of the CV for the different lambda values on the a log scale. The red dotted line shows the lambda for which minimum MSE was obtained. See @ ef(fig:err-folg-lasso-og), but this time the y-axis has the same range for all plots. Below we can see the minimum MSE for each fold. ## [1] 4503.789 2610.251 2875.691 6455.484 5482.787 And which lambda in the lambda vector resulted in the lowest prediction error on the foldsÂ´ test set. ## [1] 22.079344 1.920349 17.909237 20.591270 41.372660 19.3 Coefficient plots Figure 19.4: Coefficient map plot for the different folds. Longitude and Latitude on the x and y-axis respectively. Positive values are coloured in blue, negative values in red. 19.4 Inspect predictions from each fold Following we inspect the folds precipitation time series and the predictions made by the model. Figure 19.5: Precipitation prediction and target values in the test set in each fold. Predictions in red and target values in black. . 19.5 Inspect predictions from best CV-lambda ## [1] 7618.352 MSE mse_full RMSE sqrt(mse_full) 19.6 Summary "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
