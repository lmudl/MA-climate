Summary of Methods used so far.

1. Correlationanalysis:

Linear correlation
	SST vs averaged precipitation
	SST vs averaged precipitation (for deseasonalised data)
open/possible:
	nonlinear correlations
	correlations of predictors (SST regions)
	autocorrelation
	Cluster/Networkanalysis
	Variogramms

2. Modelevaluation

So far the first anticipated model is a Lasso model.
Before discussing possible tweaks on the LASSO (weights etc) or
model selection.
We discuss the more general problem of model evaluation.

Generally we want to obtain a good bias (approximation) - variance (estimation)
trade-off while using as much data/information as possible.

Last Block Evaluation:
We create a training set of observations that occur after each other,
time dependence is preserved.
The test set is a set of observations that are measured after the train set.
	Pros:
		Time structure is preserved
			aka: We dont use future data to predict the past.
		Independence of train and test data (after accounting for autocorrelation lags)
	Cons:
		If only one last block is used, we evaluate train/test error only once
		We don't make efficient use of the data.

Cross-Validation:
Randomly assign data to train and test.
Seems to violate the assumption of independence, because the time structure is not
taking into account.

Possible solves:

Non-dependent CV:
Assign an observation i to train and then discard all observations that i could depend on
f.e. all observations 3 months before and after i
so that these observations can not be included in the test set.
	Pro:
		Solves dependence problem
	Contra:
		Time structure is not preserved
		Eventually a lot of data is discarded!
		? Also not always same number of observations in train and test?

Last-block CV:
Create multiple train/test folds, each fold contains a train set of consecutive observations
and a test set that is oberseved afterwards, eventually with time gap to account for dependencies.
Like last block but used in multiple folds
	Pro:
		Solves dependence problem
		Time structure is preserved
		More efficient use of data than only last block
		Same number of train/test in each fold
	Contra:
		Less efficient use of data than in classic CV
		? Less number of possible folds than in classic CV (not so problematic)

https://topepo.github.io/caret/data-splitting.html, 4.3 Data Splitting for Time Series
	top left, ratio train/test always the same, but some points are more often included than others
	top right, same as above
	bottom left, ratio train/test differs, point inclusion as above
	bottom right, ratio train/test differs, point inclusion as above

A Note on the Validity of Cross-Validation for Evaluating Time Series Prediction
	also contains graphics


Stationarity of time series:
For stationary time series apparently classic CV is not so much a problem.

Possible solution:
Use both classic CV and last block CV and compare results.

4. Implementation
LASSO, choose validation set, end of time series
Choose number of CV blocks/folds, ratio train/test, length of forecast
for each lambda
	for each block
		fit lasso model given lambda and train
		predict on test
		report MSE
	report 5 point summary of MSE
Choose lambda.1SE (most conservative lambda that is still inside one SE of lambda min)

		
Questions:
-How to do prediction when time series is preprocessed to be stationary?
-


4. Open
Autoregression analysis, include autoregression of precipitation in model?
	significant timelags
Can we use an additive model to predict original target by estimating decomposed parts
Can we use specific loss function to make extreme values more important when predicting?
Other forms like stability selection/ (.632+)bootstrapping not possible because we dont
	assign observations randomly?
Can we incorporate pre existing knowledge into the lasso? F.e:
	weights, accounting for distance between Rainforest and a SST region
	grouping SST regions accounting for correlation between them

Notes:
https://robjhyndman.com/hyndsight/crossvalidation/
		