# Log for MA
04.01.20
To do:
Get coordinates for boxes of general window of interest, STAO, NTAO and Amazon basin

Done:
General window of interest: 180 W - 3 W, 40 N - 40 S (degrees, lon lat)
	STAO/ NTAO?
	amazon basin: 10 S - 0, 70 W - 55 W
Wrote expose short for björn
computed narrowed graphic for window of interest
Amazon basin first data has no values

05.01.20

precip data is complete already, but sst is separated in single files per month
download data from webpage with a function?


Done:
Get whole sst data, did it with down them all, but actually the read me contained 
	code on how to donwload alle the files

see basic-correlation.R
check if values are apparent in latest file
Write preprocessing file for sst
	-> get filenames via list.files() DONE
	-> create list with filenames DONE
	-> loop through filenames DONE
	-> create path with filename in list DONE
	-> load data DONE
	-> add each sst file data as new dimension DONE
	? -> constrain to the window we need? Here or later? -> write function ?
		if we constrain then also to_be_filled needs to get other dimensions
	-> save data TODO

Check what time frames the data is in
	-> do EDA
Compute 1 correlation
Compute time series of correlations 
Compute mean 
Check values for different time lags


14.01.21
start 09:30. plan to do 6 pomodoros so circa 3 hours

on cdo:
start cygwin 64, shell opens, cd bin, then cdo commans run
questions? how to access data outside of working directory ?

Done:
Reread some of old notes
Installed cygwin
Installed cdo
Write preprocessing file for sst
	-> constrain window we need? Here or later?
		if we constrain, then also to_be_filled needs to get other dimensions DONE solved by cdo
	-> save processed data in a new file DONE solved by cdo
	-> used mergetime *.nc


15.01.21
start 09:00 plan to do work 4 hours.

DONE:
installed cdo for R
	updated R
	updated R studio
	updated Rtools
used setreftime on test file
	-> months since 1900 (can be changes easily)


20.01.21
start 11:00 plan to work 2 hours



Notes:
so what are we doin in the first steps with the raw data?
1. use mergetime to combine the sst data DONE
2. setreftime for both files DONE maybe we dont even need this!
3. constrain time with selyear (aka selyear) should be enough
4. constrain lot/lan

DONE:
use mergetime
use setreftime
use selyear, BUT we can not save to the same file we get input from
	-> concatenate operators?
	-> save to other file
	-> maybe rename and delete old one

21.01.21

DONE:
use selyear aka select years for time filtering
use rearrange_latlon to redefine scales of lat lon
preprocess:
	create raw/sst/monthly and after mergetime raw/sst/sst-merged DONE
	inspect why mergetime "breaks" sst data DONE
	select lat lon window DONE
EDA:
	create anomalie values for each grid point DONE
	for each year and each grid point compute mean value sst DONE
	for each year and each grid point compute g_i - mean_year, f.e g_0_0 (lon,lat) - mean_1909 DONE

23.01.21

NOTES:
means ssts in paper:
for the NTAO
take all janaurars (feb, mar, etc):
for i in len(years):
	(add all i in seq(i) ) / len(i) # gives mean annual sst for one month up to a certain year

mean ssts how I understood it:
instead of each point we could take NTAO too.
for each point, each month, each year get mean
we already get monthly data so, each point,each year in january for example
compute for this point the mean of all januaries
do sst_jan_91 - sst_jan_mean_of_all_years

maybe skip this plot when we don't know which area to use now (they use the NTAO)

what to plot then?
	plot all moths and look at them?
	inspect NA's
	inspect max and min

IDEAS from rpubd post about geospatial exploratory data analysis
	local averaging all grid points over all years
	maybe see which grid points have warmed up the most over time, see time series
	autocorrelation is definitely there, right?
		autocorrelation can occur in timer but also in space
	can we explore autocorrelation together with correlation of neighboring gridpoint?
	queen based adjacency
	local Moran-Koeffizient with comparison to LOCAL mean, arithmetisches Mittel der Abweichungen von den Nachbarregionen


IDEAS fro LISA local indicators of spatial association
	spatial autocorrelation, how strong influence regions each other
	spatial non stationarity, spatial dependencies are not alike in all regions but locally different
	local moran coefficient, deviance of x_i and surrounding regions from the GLOBAL mean (different than
	above)s
		cross prod of deviance x_i and deviance sourrounding regions is
			positive, both deviances same direction, the higher the more deviance from mean
			negative, deviance x_i and deviance surrounding regions different direction
			close to zero, deviance x_i or deviance surrounding regions close to zero
		expected value, sum of all weight values/ n - 1. weights are normed by row sum, in row either 1or0
	expectation of local moran and global moran are equal
		-> global moran is mean of all local moran
		-> global moran between -1 and +1
	Getis-org G-statistics:
		local moran says nothing about "hot or cold spots"
		define distance matrix

29.01.20

DONE:
Did some plots for EDA
	read "Reconstructing coupled time series in climate systemsusing three kinds of machine-learning methods", LSTMS and Reservoir Computer seem to be interesting
	read how to read a paper

01.02.21

TODO:
Also Transformers/Attention for Time Series Data.
	https://www.reddit.com/r/MachineLearning/comments/ckaji4/d_transformers_for_time_series_data/ew2pet4/
	https://towardsdatascience.com/attention-for-time-series-classification-and-forecasting-261723e0006d
	https://arxiv.org/pdf/2001.08317.pdf
read about different data sources where they come from, how they are computed etc
decide on a data-set
write expose
get supervisor
work further on EDA
	FIRST THING PLOTTTT!!! DONE
	mean ssts (maybe NTAO/STAO):
		for each month 
			compute for each year mean temperature in ongoing fashion
			(add jan 1901 jan 1902 ... jan 1910)/len(year, here = 10) -> mean 1910
			do that for all years
			plot each month individually
	how to plot anomalies? see S3, monthly anomlies, maybe plot it for a couple of random points or NTAO/STAO
	search EDA for geospatial data
ASK niklas:
	supplementary material, and paper "we compute monthly amomalies with respect to the long-term
		mean annual cycle"
		https://cfn-live-content-bucket-iop-org.s3.amazonaws.com/journals/1748-9326/15/9/094087/2/ERL_15_9_094087_suppdata.pdf?AWSAccessKeyId=AKIAYDKQL6LTV7YY2HIK&Expires=1611855089&Signature=eYawahUfQLQSPDIB1PKHUeVfWSI%3D
	El Nino index?

READING LIST:
papers about the data sets
exploring and visualisigntime series
Exploratory Spatial Data Analysis!!!
	https://towardsdatascience.com/what-is-exploratory-spatial-data-analysis-esda-335da79026ee
	http://gispopsci.org/exploratory-spatial-data-analysis/
Animating Data Visualisation for development of the temperatures over time!!!
	https://towardsdatascience.com/animating-your-data-visualizations-like-a-boss-using-r-f94ae20843e3
search Machine Learning attention in extreme weather prediction, gives
	https://link.springer.com/article/10.1007/s10044-020-00898-1
Pattern Recognition


DONE:
papers from niklas:
	1. Reconstructing coupled time series in climate systems using three kinds of machine-learning methods,
		recommended because Tula held presentation about it.
		title, abstract, intro:
		abstract:
			coupled time series
			how well can NN learn dynamical system
			reservoir computer, backprop NN, LSTM
			RC and LSTM can infer coupling in linear and nonlinear systems
			what factors significantly influence ML reconstruction
			how do we select suitable explanatory variables for ML reconstruction
			if coupling is strongly linear -> reconstruction can be bidirectional
			if coupling is nonlinear -> direction dependent, reconstruction may be only unidirectional
			Convergent cross mapping CCM:
				determine which variable can be taken as reconstructedd one and which explanatory
					we probably dont need because need for SST vs Rain, we know that SST explains Rain
					BUT maybe inside SST pixels!
				pearson correlation may be low but CCM index may be high
		intro:
			skip
		sections:
		conclusion:
			CCM index is strong -> quality of reconstruction is direction dependent and var dependent,
				determined by coupling strength and causality between dynamical variables	
			CCM larger than 0.5 good starting point 

	2. Earth system models underestimate carbon fixation by plants in the high latitudes, recommmended bc 
		no sé
		Abstract:
			models: rising co2 concentration and climate changes -> land continues storing carbon
			BUT disagree on amount of carbon uptake
			historical co2 increase enhanced carbon fixation by photosynthesis (Gross primary production,
			GPP). Evidenced from atmospheric co2 concentration and satelitte lead area index measurements.
			Create Emergent Constraint from leaf are sensitvity to ambient (umgebend) CO2
			EC estimate of GPP is 60% larger than conventionally used multi-model average.
			-> models underestimate carbon fixation, overestimate co2 abundance
		Intro:
			to predict climate change: how much carbon in atmosphere rains there and how much is stored
			in oceans and lands. Historical increase of atm co2 concentration -> enhanced GPP, indirectly
			evident in amplified seasonal swings of atmospheric co2 concentration and increase in summer time green leaf area. Use thes observables, expressed as sensitivities to ambient co2,
			to reduce uncertainty.
		Discussion:
			model underestimation eventually due to representation of carbon-nitrogen interaction and vegetation dynamics. models that underestimate, show excessive nitrogen limitation, they also lack simulation of vegetation cover dynamcis (f.e northward shift of vascular plants (Gefäßpflanze)), plus higher productivity of shrubs and trees. models that overstimate show overly strong Co2 fertilization effect hence excessive greening, prob due to lack of nitrogen limitation. closest model estimate uses empirical approach that implicitly includes nutrient limition.
	3. An observation-based constraint on permafrost loss as a function of global warming
		recommended by Cox
		Abstract:
			permafrost component in eart system models, one of the most sensitive to warming.
			permafrost loss radically changes high-latitude hydrology and biogechemical cycling.
			-> significant feedbacks on climate change. cliamte models predict thwainf of permafrost under climate change, but widely varying magnitudes of permafrost thaw. In each model we can use present-day spatial distribution of permafrost and air temperature to infer the senitivity opof merfafrost to future global warming -> use as EC -> 20% higher estimate for sensitivity of permafrost to global warming.
		Intro:
			Connection between Mean Annual Air Temperature (MAAT) and probability of permafrost fraction
			is robust over different models and time epochs


reading list:
https://towardsdatascience.com/inferring-causality-in-time-series-data-b8b75fe52c46
file:///C:/Users/Mufasa/AppData/Local/Temp/CISE-13-6-CompSims15280.pdf
https://towardsdatascience.com/inferring-causality-in-time-series-data-b8b75fe52c46

TODO:
Also Transformers/Attention for Time Series Data.
	https://www.reddit.com/r/MachineLearning/comments/ckaji4/d_transformers_for_time_series_data/ew2pet4/
	https://towardsdatascience.com/attention-for-time-series-classification-and-forecasting-261723e0006d
	https://arxiv.org/pdf/2001.08317.pdf
read about different data sources where they come from, how they are computed etc
decide on a data-set
write expose
get supervisor
work further on EDA
	FIRST THING PLOTTTT!!! DONE
	mean ssts (maybe NTAO/STAO):
		for each month 
			compute for each year mean temperature in ongoing fashion
			(add jan 1901 jan 1902 ... jan 1910)/len(year, here = 10) -> mean 1910
			do that for all years
			plot each month individually
	how to plot anomalies? see S3, monthly anomlies, maybe plot it for a couple of random points or NTAO/STAO
	search EDA for geospatial data
ASK niklas:
	supplementary material, and paper "we compute monthly amomalies with respect to the long-term
		mean annual cycle"
		https://cfn-live-content-bucket-iop-org.s3.amazonaws.com/journals/1748-9326/15/9/094087/2/ERL_15_9_094087_suppdata.pdf?AWSAccessKeyId=AKIAYDKQL6LTV7YY2HIK&Expires=1611855089&Signature=eYawahUfQLQSPDIB1PKHUeVfWSI%3D
	El Nino index?

READING LIST:
https://towardsdatascience.com/inferring-causality-in-time-series-data-b8b75fe52c46
file:///C:/Users/Mufasa/AppData/Local/Temp/CISE-13-6-CompSims15280.pdf
https://towardsdatascience.com/inferring-causality-in-time-series-data-b8b75fe52c46
exploring and visualisigntime series
Exploratory Spatial Data Analysis!!!
	https://towardsdatascience.com/what-is-exploratory-spatial-data-analysis-esda-335da79026ee
	http://gispopsci.org/exploratory-spatial-data-analysis/
Animating Data Visualisation for development of the temperatures over time!!!
	https://towardsdatascience.com/animating-your-data-visualizations-like-a-boss-using-r-f94ae20843e3
search Machine Learning attention in extreme weather prediction, gives
	https://link.springer.com/article/10.1007/s10044-020-00898-1
Pattern Recognition

DONE:

paper about data sources:
Copernicus Data
CRU has data on precipitation and drought

Read about precipitation and drought
and decide whether to use cru or copernicus

03.02.21

DONE:
Downloaded Data
plots
	https://nordicesmhub.github.io/climate-data-tutorial/04-visualization-R/
	https://gis.stackexchange.com/questions/181586/remove-points-which-are-out-of-shapefile-or-raster-extent/181589

TODO:
inspect new data
	hadcrut data, temp over whole globe, very pixely only 5°x5°
	find out where is land where is water
fit model

TODO:
!!
file:///C:/Users/Mufasa/AppData/Local/Temp/3939-Article%20Text-6998-1-10-20190703.pdf
https://www.jstor.org/stable/pdf/25765383.pdf?refreqid=excelsior%3Ab5ce8aec306af5cbaeebbfe169ea608e



09.02.21
DONE:
Read 
Detecting Causality in Complex Ecosystems

hacrut is from 1850-2020
drought is from 1902-2019

11.02.21

factor variables in glmnet possible
problem

06.04.21

Finally started again with MA thesis
Downloaded drought data from https://crudata.uea.ac.uk/cru/data/drought/#global
Downloaded sst data from https://www.metoffice.gov.uk/hadobs/hadisst/data/HadISST_sst.nc.gz

checked on the sst_values with sst-example.R
plot(density(sst_slice, na.rm = TRUE)) showed there are some values of -1000
drop them and get nice plots

12.04.21

Preprocessing seems to be harder than expeced
for some reason cygwin does not work as it used to
doing it via ubuntu works a bit better but not completely
out of box for all the data would be nice maybe make some data overview

for sst:
I had one file that had to be merged
Hadcrut is Had sst and land temp
HadIsst is Had sst and ice temp

Maybe try all Hadcrut data and then see if land is also important?
	but problem was here that we need a land mask 
	-> Had sst data only or had ice
Had data
https://crudata.uea.ac.uk/cru/data/temperature/

For drought:
CRU https://sites.uea.ac.uk/cru/data/

can also try to update cygwin,
but anyway on Vm it will run on linux

but code will be in R for data wrangling

suddenly had sst interim selyear to had sst interim sellonlatbox
	invalid grid type

but dont need to rearrange hadisst because dimensions of long and lat
are already ok!

TODO:
check stepwise how data files change after cdo commands

13.04
preprocessing seems to work so far Hadsst and drought-19

14.04

TODO
check plots, did look ok
HadSST is not filled in though, no reanalysis, so I dont know
	how to handle, maybe use a filled in dataset
OG Paper uses ERSST and CHIRPS
ML Paper uses CRU and ERA

https://www.metoffice.gov.uk/hadobs/hadsst4/HadSST.4.0.1.0_Product_User_Guide.pdf

Use drought and compare with precip?

read about standardized precup index 
read about drought index I use

ask ML paper authors how they handled different time availability of data sets

09.06

nach plotting hadsst with plot-ggplot-data-raster seen 
that after preprocessing all values are same? Pretty large value which should not be the case, also not filled in.

15.06

preprocessed ersst, plotted some stuff
found out which time windows chirps and ersst have


16.06
start:12:50
IDEA: preprocess for all, setreftime to 1900
	and sellonlatbox

21.06
prerprocessed chirps first step
cdo -z zip setreftime,1900-1-1,00:00:00,months data/raw/drought/chirps-v2.0.monthly.nc data/interim/drought/chirps_setreftime.nc

need to preprocess chirps to see how large time variable will be

22.06
preprocessed chirps changed orientation and selected only box with relevant
location, namely amazon basin

could also plot

NEXT:
inspect timestamps so we get the right months to align etc
create two clean documents, one for each dataset.

Question:
Do I need to do sanity check on raw and preprocessed data?
Will it make sense to choose a global reftime for all datasets?
	negative timestamps possible?

25.06
check for both data set first and last dates
choose data accordingly

preprocessing ersst
	setreftime
	selyear
	sellonlatbox

load dataset check timestamps
preprocess according to shared time window

ersst, 1880 until 2014
chirps, 1981 until 2021

shared is 1981 until 2014

?Which time frame and why?
?why 1971-2000 climatology?
?are satelitte data also used?
ERSST and HADISST SST are both useful.
?we can also define more precisely what SST is?
https://www.ghrsst.org/ghrsst-data-services/products/
Warning (cdfInqContents): Coordinates variable time can't be assigned!
?select geographical window first will speed up shit way more I guess

General:
what is measured
over what time
grid cells
preprocessing
plot




TODO:
Next plot maybe a time series of the values in a certain region?
compare timestamps for m = 261 when sampled a slic

25.08

Start writing log again:

Read how to read a paper
Set up a respective template in joplin
Read first pass of "Evaluating time series forecasting models"
Found ""
Interesting evtl "Estimation Stability with Cross Validation
(ESCV)"
On Lasso and Stability Selection 
	https://stats.stackexchange.com/questions/519993/how-to-combine-stability-selection-and-model-selection-with-lasso
Stability Paths for time series
lasso with weights, oracle properties

26.08

searched for top 5 papers on cv and time series
also will check the survey on cross validation in general

geospatial analysis in R, book and articles etc
on which packages, raster vs terra etc

27.08
Start: 09:30

Words to search:
	Cross Validation for the dependent case, why again dependent errors?

General Notes:
Should we use the former precipitation as input as well, making it an 
autoregressive approach?

Questions:
In lineare models assumption: observations are independent, errors are indepndent
	AND identically distributed
Why errors independent?
	We say residuals/errors of our model are independent from the response variables
	(observation of response)
We assume that the correct model can be found with our smaller model?
When we can be sure that true model is not contained in possible smaller models
	errors must be related to outcome, how does that affect the results? Because
	it clearly violates the assumptions

Lectures:
http://www.est.uc3m.es/amalonso/esp/TSAtema4petten.pdf
https://www.youtube.com/playlist?list=PLvcbYUQ5t0UHOLnBzl46_Q6QKtFgfMGc3
http://www.cmap.polytechnique.fr/~merlet/articles/probas_massart_stf03.pdf

28.08:
Read on the use of cv for time series predictor evaluation

Quick look for time series in Elem of Stat Learning
gives "additive models can replace linear models in a wide
variety of settings for example, additive decomposition
of time series". So we could influence of trend,season,etc
on the rainfall.

Also Open: Correlationmatrix between different grid points.
Network theory with inverse correlation matrix.
Or clustering, pre information maybe can give us a bayesian approach or use weights in the lasso.
Then we can also change the loss function maybe, to
better predict high or low precipitation values.

How to deal with non stationarity?

https://stats.stackexchange.com/questions/19715/why-does-a-time-series-have-to-be-stationary

https://stats.stackexchange.com/questions/23479/why-do-we-assume-that-the-error-is-normally-distributed

https://stats.stackexchange.com/questions/120776/why-should-we-use-t-errors-instead-of-normal-errors/120787#120787

29.08

keep reading

general note: automated explorative data analylsis
	https://arxiv.org/pdf/1904.02101.pdf

30.08
start time: 09:47
finished notes and send to fabi end 14:35

28.10.21
start time: 12:34, exp 2h

TODO:
drop NA's from spi matrix 
resolution vergröbern für precip, für schnellere Laufzeiten
	wenn precip definiert wird.

